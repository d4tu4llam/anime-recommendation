# -*- coding: utf-8 -*-
"""anime_reccomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1igRVaTzhy4-QqCP1HYtCWXoodQqPR0Zw

# System Reccomendation : Anime Reccomendation
- **Nama:** HILMI DATU ALLAM
- **Email:** hilmi.allam@gmail.com
- **ID Dicoding:** datuallam

- **Dataset:** https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database?select=anime.csv

# Domain Proyek
Anime merupakan salah satu konten yang paling banyak dikonsumsi. Anime baru terus bertambah setiap tahun membuat pengguna kesulitan menemukan tontonan yang sesuai dengan preferensi mereka, dan hal ini berdampak langsung pada keberhasilan bisnis platform penyedia konten. Dengan menghadirkan sistem rekomendasi yang efektif dan personal, platform dapat meningkatkan retensi pengguna dan durasi waktu menonton, yang pada akhirnya mendorong pertumbuhan pendapatan. Studi dari Netflix menunjukkan bahwa lebih dari 80% tontonan berasal dari sistem rekomendasi, menjadikannya komponen vital dalam strategi bisnis digital mereka [1]. Selain itu, sistem ini juga membuka peluang monetisasi melalui iklan tertarget dan promosi konten eksklusif berbasis minat pengguna. MyAnimeList telah mencatat lebih dari 10.000 judul anime dalam databasenya [2], maka kehadiran sistem penyaring cerdas sangat diperlukan untuk menciptakan pengalaman pengguna yang efisien dan memuaskan. Menurut Ricci et al.[3], sistem rekomendasi yang baik dapat menjadi alat bisnis strategis yang tidak hanya meningkatkan kepuasan pengguna, tetapi juga memperkuat loyalitas dan nilai ekonomi jangka panjang.

# Mengapa masalah ini harus diselesaikan
 1. Pendorong Pertumbuhan Pendapatan Bisnis
 2. Penciptaan Pengalaman Pengguna yang Efisien dan Memuaskan

# Business Understanding

## Problem Statements

Rumusan masalah dari masalah latar belakang diatas adalah
  1. bagaimana pesebaran anime berdasarkan genre dan type distribution
  2. bagaimana member komunitas mempengaruhi rating
  3. bagaimana cara membuat sistem rekomendasi terbaik yang dapat diimplesikan ?

## GOALS

Berdasarkan problem statements, berikut tujuan dibuatnya proyek ini.
  1. Mengetahui persebaran anime berdasarkan genre dan type distribution
  2. Mengetahui member komunitas anime
  3. Menggunakan algoritma cosine similiarity maupun pemodelan machine learning untuk membuat sistem rekomendasi, lalu mengevaluasi menggunakan

## Solution Statements

1. Mengimplementasikan Exploratory Data Analysis (EDA) untuk analisis dan visualisasi data.
2. Mengimplementasikan content-based filtering approach menggunakan algoritma cosine similarity.
3. Mengimplementasikan collaborative-based filtering approach menggunakan algoritma deep learning.
4. Evaluasi Performa Model setelah model dibangun, evaluasi performa akan dilakukan menggunakan metrik seperti Precision dan Root Mean Squared Error. Ini akan memberikan wawasan tentang efektivitas model dalam merekomendasikan anime yang relevan kepada pengguna.

# Data Understanding

## 1. Mengimport Library

Pada bagian ini kita mengimport seluruh library yang diperlukan untuk menganalisis
"""

!pip install kaggle

!pip install keras

!pip install tensorflow

import os
import shutil
import zipfile
import textwrap
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report
import re

"""## Data Loading"""

# Import module yang disediakan google colab untuk kebutuhan upload file credentials
from google.colab import files
files.upload()

# Buat folder .kaggle jika belum ada
os.makedirs('/root/.kaggle', exist_ok=True)

# Pindahkan file ke folder .kaggle
shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')

# Ubah izin file agar hanya bisa diakses oleh owner
os.chmod('/root/.kaggle/kaggle.json', 600)

#Download dataset
!kaggle datasets download -d CooperUnion/anime-recommendations-database

with zipfile.ZipFile("anime-recommendations-database.zip", "r") as zip_ref:
    zip_ref.extractall("dataset")

# List files in the current directory
os.listdir("dataset")

rating=pd.read_csv("dataset/rating.csv")
anime=pd.read_csv("dataset/anime.csv")

rating.head(10)

anime.head()

"""Csv yang akan kita pakai adalah anime.csv dan rating.csv. 2 csv ini memberikan informasi berupa detail dari anime dan review masing-masing user.

### Deskripsi Variabel

arti variabel rating.csv

Variabel | Keterangan
----------|----------
user_id | nomor unik masing-masing user
anime_id | nomor unik masing-masing anime di MyAnimeList
rating | (-1 menandakan tidak rating walaupun menonton) rating user dari 10

arti variabel anime.csv

Variabel | Keterangan
----------|----------
anime_id | nomor unik masing-masing anime di MyAnimeList
name | nama lengkap anime
genre | daftar genre yang dipisahkan oleh koma
type | movie, TV, OVA, etc
episodes | berapa jumlah episode
rating | rata-rata rating dari 10
members | jumlah member komunitas anime baris ini

#### Menampilkan tipe variable rating
"""

rating.info()

print(f"Jumlah baris: {rating.shape[0]}\nJumlah kolom: {rating.shape[1]}")

"""Semua variabel bertipe int64 dan baris pada data berjumlah 7813737 denngan 3 kolom

Menampilkan tipe variable anime
"""

anime.info()

print(f"Jumlah baris: {anime.shape[0]}\nJumlah kolom: {anime.shape[1]}")

"""terdapat 4 tipe data objek yaitu name, genre, type dan episodes. 2 tipe data int64 yaitu anime_id dan members dan 1 tipe data float64 yaitu rating. Baris pada data sejumlah 12294 dengan 7 kolom

#### Mengecek Duplikat
"""

rating.duplicated().sum()

anime.duplicated().sum()

"""Terdapat 1 data duplikat pada data rating

#### Mengecek missing value
"""

pd.DataFrame({'Nilai yang Kosong':rating.isnull().sum()})

"""Memeriksa kolom rating yang -1 yaitu user tidak memberikan rating. implicit null ?"""

print({'Nilai yang Kosong': (rating['rating'] == -1).sum()})

pd.DataFrame({'Nilai yang Kosong':anime.isnull().sum()})

"""Terdapat beberapa missing value yaitu
 - genre : 62
 - type : 25
 - rating : 230

Memeriksa unique value dari genre
"""

unique_genres = set()

# Loop semua baris dan pecah genre berdasarkan koma
for genres in anime['genre'].dropna():
    for genre in genres.split(','):
        unique_genres.add(genre.strip())

# Tampilkan semua genre unik
print(sorted(unique_genres))

# Tampilkan jumlah genre unik
print(f"Total unique genres: {len(unique_genres)}")

"""Terdapat 43 unique value dari genre

#### Statistik Deskripsi

Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- Count : Jumlah sampel pada data.
- Mean : Nilai rata-rata.
- Std : Standar deviasi.
- Min : nilai minimum setiap kolom.
- 25% : Kuartil pertama adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- 50% : Kuartil kedua, atau biasa juga disebut median (nilai tengah).
- 75% : Kuartil ketiga.
- Max : Nilai maksimum.

#### Deskripsi statistik dari rating
"""

pd.set_option('display.float_format', '{:.2f}'.format)

# Tampilkan ringkasan statistik dengan format biasa
print(rating.describe())

"""Dari informasi diatas dapat disimpulkan bahwa data ini memiliki rentang rating dari -1 hingga 10 dengan rata-rata 6.14 . -1 menandakan user belum memberikan rating

#### Deskripsi statistik dari anime
"""

pd.set_option('display.float_format', '{:.2f}'.format)
# Tampilkan ringkasan statistik dengan format biasa
print(anime.describe())

"""Dapat dilihat dari informasi diatas bahwa member komunitas terbanyak ada di angka 1.013.917 yaitu 1 juta lebih member dengan yang paling sedikit 5 member. rata-rata rating berada di 6.47 dengan rating paling kecil ada di 1.67 dan rating paling tinggi ada di 10

# Exploratory Data  Analysis (EDA)

## 1. Anime Dataset EDA

Distribusi rating anime keseluruhan
"""

sns.histplot(anime['rating'], bins=20)
plt.title('Distribution of Anime Ratings')
plt.show()

"""Distribusi left-skewed dengan kebanyakan di rentang 6-7

Distribusi member anime
"""

# Salin dan urutkan data
top_anime = anime.copy()
top_anime = top_anime.dropna(subset=['name', 'members'])
top_anime_temp1 = top_anime.sort_values(["members"], ascending=False).head(10)

# Buat plot
plt.subplots(figsize=(20, 8))
p = sns.barplot(x=top_anime_temp1["name"], y=top_anime_temp1["members"],
                order=top_anime_temp1["name"], saturation=1,
                edgecolor="#1c1c1c", linewidth=2, color="#FF9F40")
p.axes.set_title("\nTop Anime Community\n", fontsize=25)
plt.ylabel("Total Member", fontsize=20)
plt.xlabel("\nAnime Name", fontsize=20)
plt.xticks(rotation=90)
for container in p.containers:
    p.bar_label(container, label_type="center", padding=6, size=15, color="black", rotation=90,
                bbox={"boxstyle": "round", "pad": 0.6, "facecolor": "orange", "edgecolor": "black", "alpha": 1})
sns.despine(left=True, bottom=True)
plt.show()

# Cetak data untuk chart
print("Labels:", top_anime_temp1["name"].tolist())
print("Data:", top_anime_temp1["members"].tolist())

"""Anime dengan member komunitas terbanyak jatuh kepada 'Death Note' dengan jumlah member 1.013.917

Distribusi anime berdasarkan genre
"""

# Pisahkan genre-genre yang digabung menjadi list
anime_genres = anime[['name', 'genre']].copy()
anime_genres['genre'] = anime_genres['genre'].str.split(', ')

# Ubah format ke bentuk "long" (satu baris = satu genre)
anime_exploded = anime_genres.explode('genre')

# Hitung distribusi genre
genre_counts = anime_exploded['genre'].value_counts()

# Visualisasi
plt.figure(figsize=(14,6))

plt.subplot(1,2,1)
sns.barplot(x=genre_counts.index[:5], y=genre_counts.values[:5], palette='Set2')
plt.xticks(rotation=45)
plt.title('Top 5 Most Common Genres')

plt.subplot(1,2,2)
plt.pie(genre_counts[:5], labels=genre_counts.index[:5], autopct='%1.1f%%', startangle=90, shadow=True,
        colors=['#ff9999','#66b3ff','#99ff99','#ffcc99','#c2c2f0'])
plt.title('Top 5 Genre Distribution')

plt.suptitle('Anime Genre Distribution')
plt.tight_layout()
plt.show()

"""Genre comedy memiliki anime terbanyak dengan jumlah 32.7%

Distribusi anime berdasarkan type
"""

# DISPLAY DISTRIBUTION ANIME BY TYPE

anime_type = anime.groupby(by='type')['name'].count()
plt.figure(figsize=(12,6))

# VISUALIZE
plt.subplot(1,2,1)
sns.barplot(x = anime_type.index, y = anime_type.values, palette='Set3')

plt.subplot(1,2,2)
type_counts = anime['type'].value_counts()
plt.pie(type_counts, labels = type_counts.index, autopct='%1.1f%%', startangle=90, shadow=True, colors=['#ff9999','#66b3ff','#99ff99','#ffcc99'])

plt.suptitle('Anime Type Distribution')
plt.show()

"""Tipe anime TV memiliki distribusi terbanyak dengan jumlah 31.1%

Top anime berdasarkan rating
"""

# Ambil 5 anime dengan rating tertinggi
top5_rating = anime.sort_values(by='rating', ascending=False).head(10)

plt.figure(figsize=(10,6))
sns.barplot(x='rating', y='name', data=top5_rating, palette='viridis')
plt.title('Top 10 Anime by Rating')
plt.xlabel('Rating')
plt.ylabel('Anime Name')
plt.show()

"""Anime terbaik berdasarkan rating adalah Taka no Tsume8: Yoshida-kun no X-Files dengan rating 10 diikuti dengan spoon-hime no swing kitchen pada urutan kedua

2. Rating dataset EDA
"""

sns.histplot(rating['rating'], bins=10)
plt.title('Distribution of User Ratings')
plt.show()

"""Distribusi left-skewed dengan kebanyakan di rentang 7-8 dan terdapat outliers yaitu -1 yang nantinya akan di hilangkan

#Data Preparation

Data preprocessing akan dilakukan pada model masing-masing

## Data Cleaning

Melakukan penghapusan pada baris yang genre null dan mengisi type yang kosong dengan yang paling umum.
"""

#Menghapus baris yang genrenya kosong
anime = anime[anime['genre'].notnull()]
#isi type kosong dengan yang paling umum
anime['type'].fillna(anime['type'].mode()[0], inplace=True)

#Drop baris dengan rating null
anime = anime.dropna(subset=["rating"])

"""drop duplikat"""

anime=anime.drop_duplicates()

"""drop null pada rating"""

#ganti -1 jadi NaN sebelumnya
rating.replace(-1, np.nan, inplace=True)
rating.dropna(inplace=True)

print(anime.isnull().sum())
print(rating.isnull().sum())

"""Pada nama anime terdapat banyak simbol akan dibersihkan dengan regex"""

def text_cleaning(text):
    text = re.sub(r'&quot;', '', text)
    text = re.sub(r'.hack//', '', text)
    text = re.sub(r'&#039;', '', text)
    text = re.sub(r'A&#039;s', '', text)
    text = re.sub(r'I&#039;', 'I\'', text)
    text = re.sub(r'&amp;', 'and', text)

    return text

anime['name'] =anime['name'].apply(text_cleaning)

"""#Modelling

## Content Based Filtering

### TF-IDF Vectorizer

### Data preparation
"""

# Salin fulldata untuk menghindari perubahan pada DataFrame asli
df_content = anime.copy()

# Pisahkan genre berdasarkan koma (dengan spasi opsional) dan gabungkan dengan spasi
df_content["genre"] = df_content["genre"].str.split(',').apply(lambda genres: ' '.join([g.strip().replace(' ', '_') for g in genres]))
  # Ubah "Drama, Romance" jadi "Drama Romance"

"""### TF-IDF Vectorizer"""

# Inisialisasi TfidfVectorizer untuk ekstraksi fitur genre
tfidf = TfidfVectorizer()


# Ubah genre menjadi matriks TF-IDF
tfidf_matrix = tfidf.fit_transform(df_content["genre"])  # Buat vektor numerik untuk genre
tfidf_matrix.shape

"""Jumlah genre sudah benar 44, (43 + 1 yaitu nama)"""

tfidf_matrix.todense()

"""tabel berisi nama anime beserta genre berdasarkan TF-IDF yang telah diinisiasi."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns = tfidf.get_feature_names_out(),
    index = df_content.name
)

"""### Cosine Similarity

Pada proyek ini content based filtering akan digunakan cosine similarity untuk mencari kemiripan anime
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""tabel berisi cosine similarity anime"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama anime
cosine_sim_df = pd.DataFrame(cosine_sim, index=df_content['name'], columns=df_content['name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap anime
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Test Sistem Rekomendasi"""

def recommendations_content(name, similarity_data=cosine_sim_df, items=df_content[['name','genre', 'rating']], k=10):

    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,name].to_numpy().argpartition(range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop name agar nama anime yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(name, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

df_content[df_content['name']=="Doraemon"]

recommended_anime = recommendations_content('Doraemon')
recommended_anime

"""Dari hasil rekomendasi berdasarkan genre berhasil memberikan rekomendasi sebanyak 10 rekomendasi"""

def relevan(rekomendasi,df_content, anime,overlap_threshold=0.9):
    genre_asal = df_content[df_content['name']==anime]['genre'].values[0]
    rekomendasi = set(rekomendasi.split(' '))
    genre_asal = set(genre_asal.split(' '))
    common_genres = rekomendasi.intersection(genre_asal)
    overlap = len(common_genres) / len(rekomendasi) if rekomendasi else 0
    return overlap >= overlap_threshold

recommended_anime['relevan'] = recommended_anime['genre'].apply(
    lambda x: relevan(x,df_content, "Doraemon")
)
# Prediksi yang benar disini ketika genre pada rekomendasi melebihi
jumlah_prediksi = len(recommended_anime)
jumlah_relevan = recommended_anime['relevan'].sum()
precision = jumlah_relevan / jumlah_prediksi
print(f"\nPrecision: {precision:.4f}")


print("\nRecommended Anime:\n")
print(recommended_anime[['name', 'genre', 'rating', 'relevan']])

"""## Collaborative Filtering

### Data preparation

Dikarenakan data yang sangat besar kita akan mengambil 500 user unik saja dengan sampling
"""

sampled_users = rating['user_id'].drop_duplicates().sample(n=500, random_state=42)
df_collab = rating[rating['user_id'].isin(sampled_users)]

df_collab.shape

# Mengubah user_id menjadi list tanpa nilai yang sama
user_ids = df_collab['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding user_id
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke user_id
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

# Mengubah anime_id menjadi list tanpa nilai yang sama
anime_ids = df_collab['anime_id'].unique().tolist()

# Melakukan proses encoding anime_id
anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}

# Melakukan proses encoding angka ke anime_id
anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

# Mapping user_id ke dataframe user
df_collab['user'] = df_collab['user_id'].map(user_to_user_encoded)

# Mapping place_id ke dataframe anime
df_collab['anime'] = df_collab['anime_id'].map(anime_to_anime_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah resto
num_anime = len(anime_encoded_to_anime)
print(num_anime)

# Mengubah rating menjadi nilai float
df_collab['rating'] = df_collab['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = df_collab['rating'].min()

# Nilai maksimal rating
max_rating = df_collab['rating'].max()

print('Number of User: {}, Number of anime: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

"""### Split dataset"""

# Mengacak dataset
df_collab = df_collab.sample(frac=1, random_state=42)
df_collab

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df_collab[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df_collab['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df_collab.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""### Training"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.anime_embedding = layers.Embedding( # layer embeddings anime
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1) # layer embedding anime bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    anime_vector = self.anime_embedding(inputs[:, 1]) # memanggil layer embedding 3
    anime_bias = self.anime_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2)

    x = dot_user_anime + user_bias + anime_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_anime, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 10,
    validation_data = (x_val, y_val)
)

"""### Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Rekomendasi Anime"""

anime_df = anime.copy()
df = rating
# Mengambil sample user and validate
user_id = df_collab['user_id'].sample(1).iloc[0]
if user_id not in user_to_user_encoded:
    raise ValueError(f"User ID {user_id} not found in user_to_user_encoded mapping. Please check your data.")

# Get anime watched by the user
anime_watched_by_user = df_collab[df_collab['user_id'] == user_id]

# Get anime not watched by the user
anime_not_watched = anime_df[~anime_df['anime_id'].isin(anime_watched_by_user['anime_id'].values)]['anime_id']
anime_not_watched = list(set(anime_not_watched).intersection(set(anime_to_anime_encoded.keys())))

# Convert anime_not_watched to encoded values
anime_not_watched_encoded = [anime_to_anime_encoded[x] for x in anime_not_watched]

# Get encoded user ID
user_encoder = user_to_user_encoded[user_id]  #agar tidak none

# Create user_anime_array with proper shape and dtype
user_anime_array = np.array(
    [[user_encoder, anime_id] for anime_id in anime_not_watched_encoded],
    dtype=np.int32  # Ensure integer dtype
)

# Verify no None values
if np.any(user_anime_array == None):
    raise ValueError("user_anime_array contains None values. Check user_to_user_encoded and anime_to_anime_encoded.")
print(user_anime_array)

# Predict ratings
ratings = model.predict(user_anime_array).flatten()

# Get top 10 recommendations
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime[anime_not_watched_encoded[x]] for x in top_ratings_indices
]

# Print recommendations
print(f'Showing recommendations for user: {user_id}')
print('===' * 9)
print('Anime with high ratings from user')
print('----' * 8)

top_anime_user = (
    anime_watched_by_user.sort_values(by='rating', ascending=False)
    .head(5)
    .anime_id.values
)

anime_df_rows = anime_df[anime_df['anime_id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(f'{row.name}: {row.genre}')

print('----' * 8)
print('Top 10 anime recommendations')
print('----' * 8)

recommended_anime = anime_df[anime_df['anime_id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(f'{row.name}: {row.genre}')

"""# Referensi

[1] Gufy. How Netflix’s Recommendation Engine Drives Success. Diakses pada 1 Juni 2025 dari https://www.gufy.com.au/post/netflixs-recommendation-engine#:~:text=In%20the%20world%20of%20streaming,also%20significantly%20improved%20user%20retention.

[2] MyAnimeList Stats. (2024). Diakses pada 1 Juni 2025 dari https://myanimelist.net/topanime.php?limit=20000

[3] Ricci, F., Rokach, L., & Shapira, B. (2011). Recommender Systems Handbook. Springer.

[4] Dicoding. Diakses pada 1 Juni 2025 dari https://www.dicoding.com/academies/319/corridor
"""